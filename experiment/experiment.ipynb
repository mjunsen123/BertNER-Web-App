{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"RGU is a university located in Aberdeen, south east part of Scotland\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'BertForSequenceClassification' is not supported for ner. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BloomForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'EsmForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'YosoForTokenClassification'].\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"RGU is a university located in Aberdeen, south east part of Scotland\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ner_results \u001b[39m=\u001b[39m nlp(example)\n\u001b[1;32m      2\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ner_results)):\n",
      "File \u001b[0;32m~/miniforge3/envs/bertner/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:216\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39moffset_mapping\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m offset_mapping\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/bertner/lib/python3.10/site-packages/transformers/pipelines/base.py:1084\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1077\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1078\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m     )\n\u001b[1;32m   1083\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1084\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/miniforge3/envs/bertner/lib/python3.10/site-packages/transformers/pipelines/base.py:1092\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1090\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[1;32m   1091\u001b[0m model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m-> 1092\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpostprocess(model_outputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpostprocess_params)\n\u001b[1;32m   1093\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/bertner/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:272\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.postprocess\u001b[0;34m(self, model_outputs, aggregation_strategy, ignore_labels)\u001b[0m\n\u001b[1;32m    267\u001b[0m     offset_mapping \u001b[39m=\u001b[39m offset_mapping\u001b[39m.\u001b[39mnumpy() \u001b[39mif\u001b[39;00m offset_mapping \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    269\u001b[0m pre_entities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather_pre_entities(\n\u001b[1;32m    270\u001b[0m     sentence, input_ids, scores, offset_mapping, special_tokens_mask, aggregation_strategy\n\u001b[1;32m    271\u001b[0m )\n\u001b[0;32m--> 272\u001b[0m grouped_entities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(pre_entities, aggregation_strategy)\n\u001b[1;32m    273\u001b[0m \u001b[39m# Filter anything that is in self.ignore_labels\u001b[39;00m\n\u001b[1;32m    274\u001b[0m entities \u001b[39m=\u001b[39m [\n\u001b[1;32m    275\u001b[0m     entity\n\u001b[1;32m    276\u001b[0m     \u001b[39mfor\u001b[39;00m entity \u001b[39min\u001b[39;00m grouped_entities\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m entity\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mentity\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_labels\n\u001b[1;32m    278\u001b[0m     \u001b[39mand\u001b[39;00m entity\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mentity_group\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_labels\n\u001b[1;32m    279\u001b[0m ]\n",
      "File \u001b[0;32m~/miniforge3/envs/bertner/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:346\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.aggregate\u001b[0;34m(self, pre_entities, aggregation_strategy)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mfor\u001b[39;00m pre_entity \u001b[39min\u001b[39;00m pre_entities:\n\u001b[1;32m    345\u001b[0m     entity_idx \u001b[39m=\u001b[39m pre_entity[\u001b[39m\"\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39margmax()\n\u001b[0;32m--> 346\u001b[0m     score \u001b[39m=\u001b[39m pre_entity[\u001b[39m\"\u001b[39;49m\u001b[39mscores\u001b[39;49m\u001b[39m\"\u001b[39;49m][entity_idx]\n\u001b[1;32m    347\u001b[0m     entity \u001b[39m=\u001b[39m {\n\u001b[1;32m    348\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mentity\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mid2label[entity_idx],\n\u001b[1;32m    349\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m: score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m: pre_entity[\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    354\u001b[0m     }\n\u001b[1;32m    355\u001b[0m     entities\u001b[39m.\u001b[39mappend(entity)\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "ner_results = nlp(example)\n",
    "counter = 0\n",
    "for index in range(len(ner_results)):\n",
    "    \n",
    "    ner_results[index][\"parentEntity\"] = ner_results[index][\"entity\"][-3:]\n",
    "    if ner_results[index][\"entity\"][0] == \"B\":\n",
    "        ner_results[index][\"beginning\"] = True\n",
    "        counter += 1\n",
    "    else:\n",
    "        ner_results[index][\"beginning\"] = False\n",
    "    ner_results[index][\"groupNER\"] = counter\n",
    "\n",
    "df = pd.DataFrame(ner_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parentEntity</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>RGU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Aberdeen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Scotland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parentEntity      word\n",
       "0          ORG       RGU\n",
       "3          LOC  Aberdeen\n",
       "4          LOC  Scotland"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.groupby(['groupNER']).aggregate({'start':'min','end':'max'}).reset_index()\n",
    "# df = df.sort_values(by=['start']).reset_index()\n",
    "df['word'] = df.groupby(['groupNER'])['word'].transform(lambda x: ' '.join(x))\n",
    "df['word'] = df['word'].apply(lambda x: x.replace('#',''))\n",
    "df['word'] = df['word'].apply(lambda x: x.replace(' ',''))\n",
    "# df = df.groupby(['groupNER','parentEntity','word','beginning']).aggregate({'start':'min','end':'max'}).reset_index()\n",
    "df = df[df['beginning']==True]\n",
    "df = df[[\"parentEntity\",\"word\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcessing(input):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "        languageModel = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "        ner_results = languageModel(input)\n",
    "\n",
    "        counter = 0\n",
    "        for index in range(len(ner_results)):\n",
    "            ner_results[index][\"parentEntity\"] = ner_results[index][\"entity\"][-3:]\n",
    "            if ner_results[index][\"entity\"][0] == \"B\":\n",
    "                ner_results[index][\"beginning\"] = True\n",
    "                counter += 1\n",
    "            else:\n",
    "                ner_results[index][\"beginning\"] = False\n",
    "            ner_results[index][\"groupNER\"] = counter\n",
    "\n",
    "        df = pd.DataFrame(ner_results)\n",
    "        df['word'] = df.groupby(['groupNER'])['word'].transform(lambda x: ' '.join(x))\n",
    "        df['word'] = df['word'].apply(lambda x: x.replace('#',''))\n",
    "        df['word'] = df['word'].apply(lambda x: x.replace(' ',''))\n",
    "        \n",
    "        df = df[df['beginning']==True]\n",
    "        df = df[[\"parentEntity\",\"word\"]]\n",
    "        js = df.to_json(orient = \"records\")\n",
    "        return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightWord(js,text):\n",
    "    \n",
    "    json_data = json.loads(js)\n",
    "    html = '<p>'\n",
    "    for word in text.split():\n",
    "        highlighted = False\n",
    "        for item in json_data:\n",
    "            if item['word'] == word:\n",
    "                html += f'<mark>{word}</mark> '\n",
    "                highlighted = True\n",
    "                break\n",
    "        if not highlighted:\n",
    "            html += f'{word} '\n",
    "    html += '</p>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"RGU is a university located in Aberdeen, south east part of Scotland\"\n",
    "js = postProcessing(input)\n",
    "html = highlightWord(js,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"parentEntity\":\"ORG\",\"word\":\"RGU\"},{\"parentEntity\":\"LOC\",\"word\":\"Aberdeen\"},{\"parentEntity\":\"LOC\",\"word\":\"Scotland\"}]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><mark>RGU</mark> is a university located in Aberdeen, south east part of <mark>Scotland</mark> </p>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>beginning</th>\n",
       "      <th>parentEntity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.997546</td>\n",
       "      <td>1</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>2</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.978134</td>\n",
       "      <td>3</td>\n",
       "      <td>ORG</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>0.995686</td>\n",
       "      <td>9</td>\n",
       "      <td>LOC</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>15</td>\n",
       "      <td>LOC</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity     score  index word  start  end  beginning parentEntity\n",
       "0  B-ORG  0.997546      1  ORG      0    1       True          ORG\n",
       "1  I-ORG  0.973958      2  ORG      1    2      False          ORG\n",
       "2  I-ORG  0.978134      3  ORG      2    3      False          ORG\n",
       "3  B-LOC  0.995686      9  LOC     31   39       True          LOC\n",
       "4  B-LOC  0.999581     15  LOC     60   68       True          LOC"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"groupStart\"] =  df[\"start\"]\n",
    "df[\"beginning\"] = df[\"entity\"].apply(lambda x: True if x[0] == \"B\" else False)\n",
    "# df[\"groupStart\"] = df.apply(lambda x: groupStart(x[\"start\"],x[\"beginning\"],x[\"groupStart\"]),axis=1)\n",
    "df[\"parentEntity\"] = df[\"entity\"].apply(lambda x:x[-3:])\n",
    "df[\"score\"]=df[\"score\"].astype(\"float64\")\n",
    "df[\"entity\"]=df[\"entity\"].astype(\"string\")\n",
    "df[\"word\"]=df[\"parentEntity\"].astype(\"string\")\n",
    "df[\"parentEntity\"]=df[\"parentEntity\"].astype(\"string\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = df.to_json(orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(js)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d698bc0177e67eb3bbeac456b58a6add8f1443905d28ae5c0dce6936a725358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
